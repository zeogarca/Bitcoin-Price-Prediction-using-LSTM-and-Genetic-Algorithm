{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TX57bWdiGE-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import Dataset\n",
        "import fastai.tabular.all as ft\n",
        "from fastai.callback.tracker import EarlyStoppingCallback\n",
        "\n",
        "#decodificar un cromosoma binario a hiperparametros\n",
        "def decode_chromosome(chrom):\n",
        "    # cada variable representa cad hiperparemetro\n",
        "    seq_len_bits = chrom[0:6] #bits para longitud\n",
        "    hidden_bits = chrom[6:8] #bits para tamaño de la capa oculta\n",
        "    dropout_bits = chrom[8:14] #para dropout\n",
        "    lr_bits = chrom[14:24] # bits para learning rate\n",
        "    batch_bits = chrom[24:26] # bits para tamaño del batch\n",
        "\n",
        "    # convertir bits a número entero\n",
        "    seq_len = int(seq_len_bits, 2) % 41 + 20 # hacer el mapeo al rango\n",
        "\n",
        "    # para tamaño del hidden\n",
        "    hidden_opts = [32, 64, 128]\n",
        "    hidden_size = hidden_opts[int(hidden_bits, 2) % 3]\n",
        "\n",
        "    # convertir bits a valor decimla entre 0-0.4\n",
        "    dropout = int(dropout_bits, 2) / 100\n",
        "    dropout = min(dropout, 0.4)\n",
        "\n",
        "    # bits a escala logaritmica\n",
        "    lr = 10 ** (-4 + int(lr_bits, 2) / 1023 * 2)\n",
        "\n",
        "    # para tamaño del batch\n",
        "    batch_opts = [32, 64, 128]\n",
        "    batch_size = batch_opts[int(batch_bits, 2) % 3]\n",
        "\n",
        "    #diccionario con los hiperparametros decodificados\n",
        "    return {\n",
        "        'seq_len': seq_len,\n",
        "        'hidden_size': hidden_size,\n",
        "        'dropout': dropout,\n",
        "        'lr': lr,\n",
        "        'batch_size': batch_size\n",
        "    }\n",
        "\n",
        "\n",
        "# fitness de un cromosoma\n",
        "def fitness(chromosome):\n",
        "    try:\n",
        "        # decodifando hiperparametros del cromosoma\n",
        "        params = decode_chromosome(chromosome)\n",
        "        seq_len = params['seq_len']\n",
        "        hidden_size = params['hidden_size']\n",
        "        dropout = params['dropout']\n",
        "        lr = params['lr']\n",
        "        batch_size = params['batch_size']\n",
        "\n",
        "        # train_ds = BTC_ds(T[:-1000], seq_len)\n",
        "        # valid_ds = BTC_ds(T[-1000 - seq_len:], seq_len)\n",
        "\n",
        "        # checar que el tamaño del dataset sea suficiente para el batch\n",
        "        if len(train_ds) < batch_size or len(valid_ds) < batch_size:\n",
        "            return 1e6\n",
        "\n",
        "        dls = ft.DataLoaders.from_dsets(train_ds, valid_ds, bs=batch_size, device='cuda:0')\n",
        "        model = BitcoinLSTM(input_size=1, hidden_size=hidden_size, num_layers=2, dropout=dropout)\n",
        "\n",
        "        learn = ft.Learner(\n",
        "            dls,\n",
        "            model,\n",
        "            loss_func=ft.MSELossFlat(),\n",
        "            opt_func=ft.ranger,\n",
        "            cbs=EarlyStoppingCallback(monitor='valid_loss', patience=3)\n",
        "        )\n",
        "\n",
        "        learn.fit_one_cycle(10, lr)\n",
        "        val_loss = learn.validate()[0]\n",
        "        print(f\"Params: {params}, Val Loss: {val_loss:.6f}\")\n",
        "        return val_loss.item()\n",
        "\n",
        "    except Exception as e:\n",
        "        # si hay error, devolver un valor de fitness muy malo\n",
        "        print(f\"Error: {e}\")\n",
        "        return 1e6"
      ]
    }
  ]
}