{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hg4zvPnFimD5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNvitBe7iYKQ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import gc\n",
        "from typing import Dict, List, Tuple\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class LSTM_PreciosBitcoin(torch.nn.Module):\n",
        "    \"\"\"Red LSTM para predicción de precios de Bitcoin.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            entrada: int,\n",
        "            oculto: int,\n",
        "            capas: int,\n",
        "            dropout: float\n",
        "        ) -> None:\n",
        "        super(LSTM_PreciosBitcoin, self).__init__()\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size=entrada,\n",
        "            hidden_size=oculto,\n",
        "            num_layers=capas,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = torch.nn.Linear(oculto, 1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "def crear_secuencias(\n",
        "        datos: np.ndarray,\n",
        "        longitud_secuencia: int\n",
        "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Prepara secuencias deslizantes para entrenamiento LSTM.\"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(len(datos) - longitud_secuencia):\n",
        "        X.append(datos[i:i+longitud_secuencia])\n",
        "        y.append(datos[i+longitud_secuencia])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def dividir_conjuntos(\n",
        "        X: np.ndarray,\n",
        "        y: np.ndarray,\n",
        "        prueba: float = 0.2,\n",
        "        mezclar: bool = False\n",
        "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"Divide los datos en conjuntos de entrenamiento y validación.\"\"\"\n",
        "    return train_test_split(X, y, test_size=prueba, shuffle=mezclar)\n",
        "\n",
        "def entrenar_modelo(\n",
        "        modelo: torch.nn.Module,\n",
        "        X_ent: torch.Tensor,\n",
        "        y_ent: torch.Tensor,\n",
        "        X_val: torch.Tensor,\n",
        "        y_val: torch.Tensor,\n",
        "        epocas: int = 2,\n",
        "        lr: float = 0.001\n",
        "    ) -> float:\n",
        "    \"\"\"Entrena el modelo LSTM y evalúa en conjunto de validación.\"\"\"\n",
        "    criterio = torch.nn.MSELoss()\n",
        "    optimizador = torch.optim.Adam(modelo.parameters(), lr=lr)\n",
        "\n",
        "    for _ in range(epocas):\n",
        "        modelo.train()\n",
        "        optimizador.zero_grad()\n",
        "        salida = modelo(X_ent)\n",
        "        perdida = criterio(salida, y_ent)\n",
        "        perdida.backward()\n",
        "        optimizador.step()\n",
        "\n",
        "    modelo.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = modelo(X_val)\n",
        "        perdida_val = criterio(preds, y_val).item()\n",
        "    return perdida_val\n",
        "\n",
        "def algoritmo_genetico_lstm(\n",
        "        serie_temporal: torch.Tensor,\n",
        "        tamano_poblacion: int = 4,\n",
        "        generaciones: int = 2,\n",
        "        max_muestras: int = 100_000\n",
        "    ) -> Dict[str, float]:\n",
        "    \"\"\"Implementa un algoritmo genético para optimizar hiperparámetros de una red LSTM.\n",
        "\n",
        "    Parámetros:\n",
        "        serie_temporal (torch.Tensor): Serie temporal de entrada para entrenamiento\n",
        "        tamano_poblacion (int): Número de individuos por generación (default 4)\n",
        "        generaciones (int): Número de iteraciones evolutivas (default 2)\n",
        "        max_muestras (int): Límite de muestras para evitar saturación de RAM (default 100,000)\n",
        "\n",
        "    Retorna:\n",
        "        Dict[str, float]: Mejor conjunto de hiperparámetros encontrado\n",
        "    \"\"\"\n",
        "\n",
        "    def crear_individuo() -> Dict[str, float]:\n",
        "        \"\"\"Genera un individuo con hiperparámetros aleatorios.\"\"\"\n",
        "        individuo = {\n",
        "            'longitud_secuencia': random.randint(10, 50),\n",
        "            'tamano_capa_oculta': random.choice([16, 32, 64, 128]),\n",
        "            'num_capas': random.choice([1, 2, 3]),\n",
        "            'dropout': random.uniform(0.0, 0.5),\n",
        "            'tasa_aprendizaje': random.uniform(0.0005, 0.01)\n",
        "        }\n",
        "        if individuo['num_capas'] == 1:\n",
        "            individuo['dropout'] = 0.0\n",
        "        return individuo\n",
        "\n",
        "    def evaluar_aptitud(individuo: Dict[str, float]) -> Tuple[float, Dict[str, float]]:\n",
        "        \"\"\"Evalúa un individuo mediante el entrenamiento del modelo LSTM.\"\"\"\n",
        "        try:\n",
        "            # Preparación de datos\n",
        "            muestra = serie_temporal[:max_muestras]\n",
        "            X, y = crear_secuencias(muestra, individuo['longitud_secuencia'])\n",
        "\n",
        "            if len(X) < 500:\n",
        "                return float('inf'), individuo  # Penaliza secuencias muy cortas\n",
        "\n",
        "            # División train/validation\n",
        "            X_ent, X_val, y_ent, y_val = dividir_conjuntos(X, y, prueba=0.2, mezclar=False)\n",
        "\n",
        "            # Conversión a tensores\n",
        "            X_ent = torch.tensor(X_ent, dtype=torch.float32).unsqueeze(-1)\n",
        "            y_ent = torch.tensor(y_ent, dtype=torch.float32).view(-1, 1)\n",
        "            X_val = torch.tensor(X_val, dtype=torch.float32).unsqueeze(-1)\n",
        "            y_val = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "            # Entrenamiento del modelo\n",
        "            modelo = LSTM_PreciosBitcoin(\n",
        "                entrada=1,\n",
        "                oculto=individuo['tamano_capa_oculta'],\n",
        "                capas=individuo['num_capas'],\n",
        "                dropout=individuo['dropout']\n",
        "            )\n",
        "\n",
        "            perdida = entrenar_modelo(\n",
        "                modelo=modelo,\n",
        "                X_ent=X_ent,\n",
        "                y_ent=y_ent,\n",
        "                X_val=X_val,\n",
        "                y_val=y_val,\n",
        "                epocas=2,\n",
        "                lr=individuo['tasa_aprendizaje']\n",
        "            )\n",
        "\n",
        "            return perdida, individuo\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error en evaluación: {str(e)}\")\n",
        "            return float('inf'), individuo\n",
        "\n",
        "        finally:\n",
        "            # Liberación de memoria\n",
        "            if 'modelo' in locals():\n",
        "                del modelo\n",
        "            if 'X_ent' in locals():\n",
        "                del X_ent, y_ent, X_val, y_val\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "    def cruzar_individuos(\n",
        "            padre1: Dict[str, float],\n",
        "            padre2: Dict[str, float]\n",
        "        ) -> Dict[str, float]:\n",
        "        \"\"\"Realiza cruce y mutación para crear un nuevo individuo.\"\"\"\n",
        "        hijo = {\n",
        "            'longitud_secuencia': random.choice([padre1['longitud_secuencia'], padre2['longitud_secuencia']]),\n",
        "            'tamano_capa_oculta': random.choice([padre1['tamano_capa_oculta'], padre2['tamano_capa_oculta']]),\n",
        "            'num_capas': random.choice([padre1['num_capas'], padre2['num_capas']]),\n",
        "            'dropout': max(0.0, min(0.5, (padre1['dropout'] + padre2['dropout']) / 2 + random.uniform(-0.05, 0.05))),\n",
        "            'tasa_aprendizaje': max(0.0001, min(0.01, (padre1['tasa_aprendizaje'] + padre2['tasa_aprendizaje']) / 2 + random.uniform(-0.001, 0.001)))\n",
        "        }\n",
        "\n",
        "        if hijo['num_capas'] == 1:\n",
        "            hijo['dropout'] = 0.0\n",
        "\n",
        "        return hijo\n",
        "\n",
        "    # Inicialización de población\n",
        "    poblacion = [crear_individuo() for _ in range(tamano_poblacion)]\n",
        "\n",
        "    # Ciclo evolutivo\n",
        "    for generacion in range(1, generaciones + 1):\n",
        "        # Evaluación de aptitud\n",
        "        resultados = []\n",
        "        for individuo in poblacion:\n",
        "            perdida, ind = evaluar_aptitud(individuo)\n",
        "            if perdida < float('inf'):  # Solo considerar individuos válidos\n",
        "                resultados.append((perdida, ind))\n",
        "\n",
        "        # Validación de resultados\n",
        "        if len(resultados) < 2:\n",
        "            print(\"⚠️ Advertencia: Insuficientes individuos válidos\")\n",
        "            break\n",
        "\n",
        "        # Selección de mejores\n",
        "        resultados.sort(key=lambda x: x[0])\n",
        "        mejores = resultados[:max(2, tamano_poblacion // 2)]\n",
        "        nueva_poblacion = [ind for _, ind in mejores]\n",
        "\n",
        "        # Reproducción\n",
        "        while len(nueva_poblacion) < tamano_poblacion:\n",
        "            if len(nueva_poblacion) >= 2:\n",
        "                padre1, padre2 = random.sample(nueva_poblacion, 2)\n",
        "            else:\n",
        "                padre1 = padre2 = nueva_poblacion[0]\n",
        "\n",
        "            nuevo_individuo = cruzar_individuos(padre1, padre2)\n",
        "            nueva_poblacion.append(nuevo_individuo)\n",
        "\n",
        "        poblacion = nueva_poblacion\n",
        "        print(f\"🧬 Generación {generacion}/{generaciones} | Mejor pérdida: {mejores[0][0]:.6f}\")\n",
        "\n",
        "    return resultados[0][1] if resultados else crear_individuo()\n",
        "\n",
        "def cargar_datos(ruta: str) -> torch.Tensor:\n",
        "    \"\"\"Carga y preprocesa los datos de precios de Bitcoin.\"\"\"\n",
        "    df = pd.read_csv(ruta)\n",
        "    df['Date'] = pd.to_datetime(df['Timestamp'], unit='s')\n",
        "    df = df.set_index('Date')[['Close']].copy()\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    escalador = MinMaxScaler()\n",
        "    cierre_escalado = escalador.fit_transform(df[['Close']].values).flatten()\n",
        "\n",
        "    return torch.tensor(cierre_escalado, dtype=torch.float32)\n",
        "\n",
        "def entrenar_modelo_final(\n",
        "        serie_temporal: torch.Tensor,\n",
        "        mejores_hiperparametros: Dict[str, float],\n",
        "        epocas: int = 20\n",
        "    ) -> LSTM_PreciosBitcoin:\n",
        "    \"\"\"Entrena el modelo final con los mejores hiperparámetros encontrados.\"\"\"\n",
        "    longitud_secuencia = mejores_hiperparametros.get('longitud_secuencia', 20)\n",
        "    X, y = crear_secuencias(serie_temporal.numpy(), longitud_secuencia)\n",
        "\n",
        "    X_ent, X_val, y_ent, y_val = dividir_conjuntos(X, y, prueba=0.2, mezclar=False)\n",
        "\n",
        "    X_ent = torch.tensor(X_ent, dtype=torch.float32).unsqueeze(-1)\n",
        "    y_ent = torch.tensor(y_ent, dtype=torch.float32).view(-1, 1)\n",
        "    X_val = torch.tensor(X_val, dtype=torch.float32).unsqueeze(-1)\n",
        "    y_val = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "    modelo = LSTM_PreciosBitcoin(\n",
        "        entrada=1,\n",
        "        oculto=mejores_hiperparametros.get('tamano_capa_oculta', 32),\n",
        "        capas=mejores_hiperparametros.get('num_capas', 3),\n",
        "        dropout=mejores_hiperparametros.get('dropout', 0.265)\n",
        "    )\n",
        "\n",
        "    entrenar_modelo(\n",
        "        modelo=modelo,\n",
        "        X_ent=X_ent,\n",
        "        y_ent=y_ent,\n",
        "        X_val=X_val,\n",
        "        y_val=y_val,\n",
        "        epocas=epocas,\n",
        "        lr=mejores_hiperparametros.get('tasa_aprendizaje', 0.0015)\n",
        "    )\n",
        "\n",
        "    return modelo\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Carga y preparación de datos\n",
        "    datos = cargar_datos(\"/content/btcusd_1-min_data.csv\")\n",
        "\n",
        "    # Optimización de hiperparámetros\n",
        "    mejores_hiperparametros = algoritmo_genetico_lstm(\n",
        "        serie_temporal=datos,\n",
        "        tamano_poblacion=4,\n",
        "        generaciones=2\n",
        "    )\n",
        "    print(\"🔍 Mejores hiperparámetros encontrados:\", mejores_hiperparametros)\n",
        "\n",
        "    # Entrenamiento del modelo final\n",
        "    modelo_final = entrenar_modelo_final(datos, mejores_hiperparametros)\n",
        "    print(\"✅ Modelo final entrenado exitosamente\")"
      ]
    }
  ]
}